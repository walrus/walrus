\documentclass[a4paper]{article}

% Table of contents depth
\setcounter{tocdepth}{3}

% Section numbering depth (zero for no numbering)
\setcounter{secnumdepth}{0}

% LaTeX package inclusions
\usepackage[english]{babel}

\usepackage{fullpage} % Page width options

\usepackage{hyperref} % Internal and external references
\usepackage{url}      % Unused?
\usepackage{breakurl} % Support for sensible line breaks in URLS

\usepackage{tabulary} % Fun with tables
\usepackage{float}    % Allows for better placement of tables etc
\usepackage{array}    % More options for tables
\usepackage{multirow} % Support for multi row columns in tables

\usepackage{graphicx} % For picture inclusion
\graphicspath{{images/}}

\usepackage[colorinlistoftodos]{todonotes} % For the inclusion of TODOs
\usepackage[toc,page]{appendix} % Generation of bibliography/appendix

% Source code inclusion
\usepackage{listings}
\lstset{
  tabsize=2,
  basicstyle = \ttfamily\small,
  columns=fullflexible
}
% Usage for the above like so:
% \begin{lstlisting}
%   CODE CODE CODE
% \end{lstlisting}

% In-line code styling (same style as listing)
\newcommand{\shell}[1]{\lstinline{#1}}

% Use roman numerals for page numbers in the contents
\pagenumbering{roman}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{\textbf{WALRUS:}\\
Exercise classification on embedded hardware}
\date{2017}
\author{
Daniel Clay\\
\emph{Supervised by Dr Thomas Heinis}\\ 
}
\maketitle
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Abstract: do this last, goes the advice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Acknowledgements: Dr Heinis et al}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Table of Contents on new page
\pagebreak
\tableofcontents
\pagebreak

% Use arabic numerals after contents
\pagenumbering{arabic}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Motivation}%%%%%%%%%%%%%%%%%%%%%%%%%




In the West, obesity is a growing problem - as of 2015, \textbf{62.9\%} of adults in the UK were either overweight or obese, a number which is still increasing.\cite{inref1}

While many people express a desire to exercise more this does not always translate into action, and one of the reasons for this is that
people often don't know how to exercise, and even if they do exercise this lack of knowledge stops or hampers them from exercising as effectively as they might be able to.

Traditionally the solution to this dilemma has been provided by people like coaches, instructors and personal trainers. They generally bring a lot of expertise and experience, and are highly effective, but the cost of hiring them can be unaffordable for many people.

With advances in technology, more and more of the tasks which personal trainers and their ilk were relied upon to do can instead be performed by machines. Companies are starting to release gadgets which can classify different exercises, normally into large groups such as 'walking' or 'cycling', but as yet they do not tell the user how well they are performing said exercise.

\subsection{Issues}%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{What makes this difficult}

\subsection{Contributions}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{As it says on the tin. List all the deliverables}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Neural Networks}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Neural networks are currently the focus of a lot of research in academia, and also the focus of a lot of commercial work to realise their potential - virtually all of the major tech companies make use of the technology, or are experimenting with it.

Because my project is centered around a novel usage of existing neural network techniques, rather than any new techniques, my research into the theory of neural networks has been relatively limited, and I have focussed on their application to my project.

Most of my general knowledge of Neural Networks comes from the third year DoC course \textbf{395 Machine Learning}\cite{bgref0}. (in particular, see the notes for the Artificial Neural Networks lectures):

As well as the course notes, the lecturers have recommended several other resources (a list of which can be found on the previously linked page), of which the paper \textit{Artifical Neural Networks: A Tutorial}\cite{bgref1} is the most relevant. This provided an overall introduction to neural networks and gave a different perspective to that given by the DoC course.

Another useful reference has been \textit{Neural Networks - Algorithms and Applications}\cite{bgref2}. This contains lots of practical information of direct relevance to the implementation of neural networks.

\subsection{ArduinoANN}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

My neural network implementation is based on \textit{ArduinoANN}\cite{bgref3}, a C implementation of a two layer feed-forward backpropagation network. 

ArduinoANN itself draws heavily on \textit{John Bullinaria's Step by Step Guide to Implementing a Neural Network in C}\cite{bgref4}.

\subsection{Embedded Systems \& The Intel Curie}%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Embedded Systems}

While most machine learning has historically done on relatively powerful desktop systems or specialised hardware, modern embedded systems are often more powerful than the desktop computers available when techniques such as back propagation were developed.\cite{bgref5}. 

As embedded systems become more powerful and more widespread, machine learning programs will be run on them much more often.

\subsubsection{The Intel Curie}

The Intel Curie is a System-On-a-Chip (SOC) with an integrated six-axis accelerometer/gyroscope and an integrated 128-neuron neural network that operates on the data from the sensors.

Despite the presence of the neural network, which Intel call the \textit{Curie Pattern Matching Engine}\cite{bgref6}, I will be implementing a separate neural network. This decision is explained in another section. \todo[inline]{link when written}

The module is currently available on an Arduino 101 board (known as the Genuino 101 outside the US), or an Intel Quark microcontroller - I will be developing using the Arduino board.

The Arduino/Genuino 101 provides a set of I/O pins, power supply, and Bluetooth connectivity for the on-board Curie module.

More information can be found at Intel's homepage for the Curie\cite{bgref6}.

Information on software dependencies can be found here. \todo[inline]{link when done}

\subsection{Bluetooth / Bluetooth Low Energy (BLE)}%%%%%%%%%%%%%%%%%%%%%%%

Bluetooth Low Energy\cite{bgref7} is a low power version of the Bluetooth standard designed to allow devices to transfer small amounts of data in an energy efficient manner. The standard debuted in 2011, and is now widely supported by Internet of Things (IoT) and mobile devices.

\subsection{Fitness Trackers}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

There are a wide variety of fitness trackers available on the market - most utilise a combination of gyroscopes, accelerometers and GPS, and more sometimes heart rate monitors, altimeters and other sensors to track the user's movements and provide feedback.

Tracking via sensors other than those available on the Intel Curie (I.E. gyroscope and accelerometer) is outside the scope of this project, so I will be ignoring this functionality in other fitness trackers.

Of these, the majority simply measure the input data and do simple analysis to provide basic data, E.G. heart rate or calories burned, but a growing number use various forms of machine learning to do more in depth analysis. 

\subsubsection{Fitbit}

Fitbit is one of the leading brands in wearables and fitness tracking. In particular, their \textit{SmartTrack}\cite{bgref8} technology aims to automatically recognise which activity the wearer is currently doing, and currently supports seven different activities.

\subsubsection{Google}

Google has a line of wearables called \textit{Android Wear}\cite{bgref9}, which make use of their \textit{Google Fit}\cite{bgref10} software (also compatible with other wearables).
Google Fit automatically detects walking, running and cycling.

\subsubsection{Optimize Fitness}

Optimize Fitness\cite{bgref11} is an iOS application that claims to use 'Powerful machine learning algorithms' to 'analyze your preferences, workout history, and goals to deliver efficient workouts that keep you improving wherever and whenever you exercise.'

\subsubsection{Boltt}

Boltt\cite{bgref12} is a startup that aims to use multiple sensors (embedded in shoes and on a wristband) along with AI to give guidance. Currently it is in the pre-order stage.

\subsubsection{Actofit}

Actofit\cite{bgref13} is another startup that recently funded via Indiegogo\cite{bgref14}. They claim to 'identify 75+ exercises, count reps, evaluate form, measure heart rate, calories burned and more' using a wristband.

\subsubsection{FocusMotion}

FocusMotion\cite{bgref15} provides an SDK that works on many different devices, and uses their sensors as input to their machine learning algorithms, which aim to classify and analyse user's movements.

\subsection{Bodyweight Exercises}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

While there is no objective standard for how most exercises should be performed, for the most common exercises there exists a broad consensus on the proper technique.

I will use these as a baseline to compare a user's movements to, and to ensure that when recording training data the examples are correct. I have used the following guides as my references.

\subsubsection{Press Ups}

The generally agreed proper technique for a press up is as follows:

\begin{itemize}
    \item Place your hands on the ground slightly more than shoulder width apart, and your feet behind you. Your body should be straight, with no sagging at the hips. You should be looking slightly ahead, not vertically downwards, and your arms should be locked out.
    \item Keeping your body straight, lower yourself down until your elbows are at a 90° angle to the floor, and upper arms are horizontal. Your elbows should remain close in to the side of your body, not splayed out to the sides.
    \item In the same manner, raise yourself back up with your arms until they lock out again.
\end{itemize}

I have used the following two articles as my reference for good technique when doing a press up:

Nerd Fitness' article \textit{How to do a Proper Push Up}\cite{bgref16}
is a good overall guide to technique, while Breaking Muscle's article \textit{Pimp Your Push Up: 3 Common Mistakes And 5 Challenging Variations}\cite{bgref17} addresses a few common issues with people's technique.

A video illustrating these points can be found on Youtube.\cite{bgref18}

\subsubsection{Sit Ups}

Opinions on proper sit up technique vary, primarily over the placement of the arms - some guides recommend crossing them over your chest, while others recommend placing your hands on the back of your head. 

LiveStrong.com\cite{bgref19} recommends placing hands behind the head, while military.com\cite{bgref20}recommends crossing your arms over your chest. 

The general opinion seems to be that either is acceptable, with the hands-behind-the-head technique considered slightly harder\cite{bgref21}.

Keeping your hands loose is generally considered a bad thing as it allows you to use them to lift your torso, rather than your abdominal muscles. 

For my reference, I will use the crossed arms technique because placing your arms behind your head encourages you to pull yourself up from the neck, rather than the waist, which the crossed arms technique avoids.

There is also not a consensus on whether it is better to anchor your feet during a sit up. For the purposes of my reference, I will be recommending unanchored feet. 

For more specific information on unanchored sit ups, the article \textit{How to Do Sit-Ups Without Anchoring Your Feet}\cite{bgref22}
The proper technique for a sit up, with the caveats above, is as follows:

\begin{itemize}
    \item Lie flat on your back, with your knees bent at a 90° angle and feet on the floor. Cross your arms over your chest and straighten your neck. and spine.
    \item Keeping your legs immobile, lift your back off the floor by flexing at the waist, and continue until your back is vertical. This should be a smooth, controlled movement not a jerk, and should not be assisted by the arms. Your neck should remain straight, but the spine can flex a little. You may find it helpful to exhale as you do this.
    \item Having reached the upright position, rest if necessary and lower yourself back down in the same manner. You may find it helpful to inhale as you do this.
\end{itemize}

This video\cite{bgref23} gives a good demonstration of good sit up technique, although it uses the hands behind the head technique.

\subsubsection{Lunges}

Opinions on proper lunge technique are fairly settled, with a strong consensus. While there are many possible varieties of lunges, including those with weights, I will concentrate on lunges using bodyweight alone.

My main source for technique was Shape.com\cite{bgref24}.

My baseline reference for good lunge technique is as follows:

\begin{itemize}
    \item Stand up straight, with shoulders relaxed and core engaged
    \item Step forwards with one leg, and lower your body until the forward knees is bent at 90° to the floor. The back knee should not touch the floor, and your upper body should remain upright.
    \item In the same manner, smoothly push back up to your starting position.
\end{itemize}

This video\cite{bgref25} illustrates good lunge technique.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Design \& Specification - Neural Network Library}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

I will be creating a C++ class-based library to facilitate the implementation of two layer feed-forward backpropagation neural networks on embedded systems, based on \todo[inline]{ArduinoANN (link to background).}

The library is designed to enable a network to be trained on a (more powerful) desktop system, and then uploaded to the embedded system for use.

Because of this, there are two core Network classes: \lstinline{Network_L} (which can be found in the file \lstinline{network-linux.hpp}) supports training and makes more extensive use of RAM, while \lstinline{Network_A} (found in the file \lstinline{network-arduino.hpp} cannot be trained and is designed to minimise RAM usage, instead storing as much data as possible in Program Memory. If the network is small enough, and an implementation of the STL is available, \lstinline{Network_L} can be run on a microcontroller.

Functions for writing and reading network configurations to and from disk can be found in the file \lstinline{network-saveload-linux.hpp}

\subsection{Language \& Dependencies}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

All three files are written to conform to the C++11 standard\cite{nnref0}. The two Linux-based files further depend on the C++ Standard Template Library, in particular the \lstinline{std::vector} data structure.

The Arduino file lacks the dependency on the STL, but itself depends on the \textit{pgmspace} library.\cite{nnref1}

\subsection{API Reference}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Network\_L API}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting} 
Network_L(int numInputNodes,
          int numHiddenNodes,
          int numOutputNodes,
          float learningRate,
          float momentum,
          float initialWeightMax,
          long trainingCycle);
\end{lstlisting}

\textbf{Description: }
Constructs a new instance of \lstinline{Network_L} in memory, initialising all nodes to zero and all weights to \lstinline{|weight| < initialWeightMax}

\textbf{Parameters: }

\lstinline{numInputNodes} The number of nodes in the input layer. Cannot be changed after initialisation.

\lstinline{numHiddenNodes} The number of nodes in the hidden layer. Cannot be changed after initialisation.

\lstinline{numOutputNodes} The number of nodes in the output layer. Cannot be changed after initialisation.

\lstinline{learningRate} The factor by which the backpropagated error is multiplied. A lower learning rate results in slower learning, but is less prone to over correction and oscillating weight changes. The learning rate should be in the range \lstinline{0 < learningRate < 1}.

\lstinline{momentum} The momentum term, which helps smooth out weight changes and avoid local minima. Must be in the range \lstinline{0 =< momentum < 1}. Setting momentum to zero is the same as backpropagation without momentum.

\lstinline{initialWeightMax} Defines the maximum absolute value of weights upon initialisation. All weights will be initialised to \lstinline{|weight| < initialWeightMax} 

\textbf{Returns}
A pointer to the newly initialised \lstinline{Network_L}.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float trainNetwork(std::vector<float> inputs,
                   std::vector<float> targets);
\end{lstlisting}

\textbf{Description: }
Trains the network on the given sets of inputs and targets using backpropagation.

\textbf{Parameters: }

\lstinline{inputs} The set of inputs to the network. Must contain \lstinline{numInputNodes} elements.

\lstinline{targets} The set of targets for the network to compare output to. Must contain \lstinline{numOutputNodes} elements.

\textbf{Returns: }
The cumulative error of the network before applying backpropagation (the sum of the differences between the outputs and the targets).

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
std::string writeReport();
\end{lstlisting}

\textbf{Description: }
Returns information about the current state of the network for display purposes.

\textbf{Parameters: } None

\textbf{Returns: }
A string which contains the current training cycle and error rate of the network.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
std::vector<float> classify(std::vector<float> inputs);
\end{lstlisting}

\textbf{Description: }
Attempts to classify the given set of inputs using the network. Unlike \lstinline{trainNetwork()}, will not modify the state of the network.

\textbf{Parameters: }

\lstinline{inputs} The set of inputs to the network. Must contain \lstinline{numInputNodes} elements.

\textbf{Returns: }
A vector containing a copy of the values of the output nodes after classification.
\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
void loadWeights(std::vector<std::vector<float>> hiddenWeights,
                 std::vector<std::vector<float>> outputWeights);
\end{lstlisting}

\textbf{Description: }
Replaces the network's weights with the values in the given vectors.

\textbf{Parameters: }

\lstinline{hiddenWeights} An \lstinline{m} x \lstinline{n} vector of vectors containing the values to replace the hidden weights with, where \lstinline{m = numInputNodes + 1} and \lstinline{n = numHiddenNodes}.

\lstinline{outputWeights} An \lstinline{m} x \lstinline{n} vector of vectors containing the values to replace the output weights with, where \lstinline{m = numHiddenNodes + 1} and \lstinline{n = numOutputNodes}.

\textbf{Returns: } Void.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
int getNumInputNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{numInputNodes}

\textbf{Parameters: } None

\textbf{Returns: }
The number nodes in the input layer.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
int getNumHiddenNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{numHiddenNodes}

\textbf{Parameters: } None

\textbf{Returns: }
The number nodes in the hidden layer.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
int getNumOutputNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{numOutputNodes}

\textbf{Parameters: } None

\textbf{Returns: }
The number nodes in the output layer.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getLearningRate() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{learningRate}

\textbf{Parameters: } None

\textbf{Returns: }
The current network learning rate.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getMomentum() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{momentum}

\textbf{Parameters: } None

\textbf{Returns: }
The current network momentum.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getInitialWeightMax() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{initialWeightMax}

\textbf{Parameters: } None

\textbf{Returns: }
The initial weight maximum value.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
long getTrainingCycle() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{trainingCycle}

\textbf{Parameters: } None

\textbf{Returns: }
The current training cycle

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getRandomFloat() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{randomFloat}

\textbf{Parameters: } None

\textbf{Returns: }
The current value of \lstinline{randomFloat}, which will be in the range \lstinline{-1.0 < randomFloat < 1.0}

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getErrorRate() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{errorRate}

\textbf{Parameters: } None

\textbf{Returns: }
The current value of the network error rate.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getAccumulatedInput() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{accumulatedInput}

\textbf{Parameters: } None

\textbf{Returns: }
The current value of the network's accumulated input.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const std::vector<float> getHiddenNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{hiddenNodes}

\textbf{Parameters: } None

\textbf{Returns: }
A \textit{copy} of the current value of the network's hidden nodes.
\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const std::vector<float> getOutputNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{outputNodes}

\textbf{Parameters: } None

\textbf{Returns: }
A \textit{copy} of the current value of the network's output nodes.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const std::vector<float> getHiddenNodesDeltas() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{hiddenNodesDeltas}, the magnitude of the difference between the target and the actual outputs for each hidden node.

\textbf{Parameters: } None

\textbf{Returns: }
A \textit{copy} of the current value of the network's hidden node deltas,

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const std::vector<float> getOutputNodesDeltas() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{outputNodesDeltas}, the magnitude of the difference between the target and the actual outputs for each output node.

\textbf{Parameters: } None

\textbf{Returns: }
A \textit{copy} of the current value of the network's output node deltas.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const std::vector<std::vector<float>> getHiddenWeights() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{hiddenWeights}

\textbf{Parameters: } None

\textbf{Returns: }
A \textit{copy} of the current value of the network's hidden weights.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const std::vector<std::vector<float>> getOutputWeights() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{outputWeights}

\textbf{Parameters: } None

\textbf{Returns: }
A \textit{copy} of the current value of the network's output weights.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const std::vector<std::vector<float>> getHiddenWeightsChanges() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{hiddenWeightsChanges}, the change to be applied to each hidden weight to compensate for it's error. Depending on when this function is called, the change may already have been applied.

\textbf{Parameters: } None

\textbf{Returns: }
A \textit{copy} of the current value of the network's hidden weights changes.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const std::vector<std::vector<float>> getOutputWeightsChanges() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{outputWeightsChanges}, the change to be applied to each output weight to compensate for it's error. Depending on when this function is called, the change may already have been applied.

\textbf{Parameters: } None

\textbf{Returns: }
A \textit{copy} of the current value of the network's hidden weights changes.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
void setLearningRate(float learningRate);
\end{lstlisting}

\textbf{Description: }
Setter for \lstinline{learningRate}

\textbf{Parameters: }

\lstinline{learningRate} The new value to set the network's learning rate to.

\textbf{Returns: } Void

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
void setMomentum(float momentum);
\end{lstlisting}

\textbf{Description: }
Setter for \lstinline{momentum}

\textbf{Parameters: }

\lstinline{learningRate} The new value to set the network's momentum to.

\textbf{Returns: } Void

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Network\_A API}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
Network_A();
\end{lstlisting}

\textbf{Description: }
Constructs a new instance of \lstinline{Network_A}, with the nodes in RAM. Relies on the presence of the network configuration in program memory.

\textbf{Parameters: } None

\textbf{Returns: }
A pointer to the newly initialised \lstinline{Network_A}.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
std::string writeReport();
\end{lstlisting}

\textbf{Description: }
Returns information about the current state of the network for display purposes.

\textbf{Parameters: } None

\textbf{Returns: }
A string which contains the current training cycle and error rate of the network.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float * classify(float inputs[]);
\end{lstlisting}
\textbf{Description: }
Attempts to classify the given set of inputs using the network.

\textbf{Parameters: }

\lstinline{inputs} The set of inputs to the network. Must contain \lstinline{numInputNodes} elements.

\textbf{Returns: }
A pointer to the array containing the values of the output nodes after classification. 
\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
int getNumInputNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{numInputNodes}

\textbf{Parameters: } None

\textbf{Returns: }
The number of nodes in the input layer.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
int getNumHiddenNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{numHiddenNodes}

\textbf{Parameters: } None

\textbf{Returns: }
The number of nodes in the hidden layer.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
int getNumOutputNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{numOutputNodes}

\textbf{Parameters: } None

\textbf{Returns: }
The number of nodes in the output layer.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getLearningRate() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{learningRate}

\textbf{Parameters: } None

\textbf{Returns: }
The current network learning rate.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getMomentum() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{momentum}

\textbf{Parameters: } None

\textbf{Returns: }
The current network momentum.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getInitialWeightMax() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{initialWeightMax}

\textbf{Parameters: } None

\textbf{Returns: }
The initial weight maximum value.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
long getTrainingCycle() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{trainingCycle}

\textbf{Parameters: } None

\textbf{Returns: }
The current training cycle

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
float getAccumulatedInput() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{accumulatedInput}

\textbf{Parameters: } None

\textbf{Returns: }
The current value of the network's accumulated input.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const float * getHiddenNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{hiddenNodes}

\textbf{Parameters: } None

\textbf{Returns: }
A (const) pointer to the array containing the current values of the hidden nodes.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
const float * getOutputNodes() const;
\end{lstlisting}

\textbf{Description: }
Getter for \lstinline{outputNodes}

\textbf{Parameters: } None

\textbf{Returns: }
A (const) pointer to the array containing the current values of the output nodes.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Save/Load API}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
Network_L *loadNetwork(std::string filename);
\end{lstlisting}

\textbf{Description: }
Reads the network configuration found in the file \lstinline{filename}, and initialises a new \lstinline{Network_L} with the configuration.

\textbf{Parameters: } 

\lstinline{filename} The filename of the configuration file to load. 

\textbf{Returns: }
A pointer to the newly initialised \lstinline{Network_L}. If \lstinline{filename} is not a valid configuration file, the function will return \lstinline{Null}

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Signature:} \begin{lstlisting}
int saveNetwork(std::string filename, Network_L *network);
\end{lstlisting}

\textbf{Description: }
Saves the given network's configuration to the given file, if necessary overwriting the existing contents of the file. 

\textbf{Parameters: } 
 
\lstinline{filename} The file to save the configuration to. If the file exists, it will be overwritten.

\lstinline{*network} The network to save the configuration of. 

\textbf{Returns: }
0 on success, or 1 if file saving was unsuccessful.

\hrulefill %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Network Configuration File Format}%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Specify network config file format. Include link to examples}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Design \& Specification - Exercise Classifier}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Overall design. Note different versions, and throughout note differences due to different versions. This is basically a specification}

\subsection{Hardware}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Overview of hardware used and specifications for alternative}

\subsubsection{Microcontroller}

The requirements of the microcontroller for this project are as follows:

\todo[inline]{finish}

\begin{description}
\item[Processor] The microcontroller's processor needs to be capable of performing a classification within 100 milliseconds, to ensure that the user receives feedback on their exercises in a short enough interval to be useful. Given \todo[inline]{the network}, the minimum clock speed is around 211KHz.\cite{dsref0}
\item[Memory] \todo[inline]{work out how much memory the damn thing takes}
\item[Storage] The microcontroller needs to have enough storage for the weights. Given \todo[inline]{the network}, this takes about 17KB not including the bootloader\cite{dsref2}.
\item[Accelerometer] The microcontroller needs to be capable of measuring acceleration on three axes through an IMU or accelerator, either onboard or via a shield.
\item[Bluetooth] The microcontroller needs to be capable of connecting over a Bluetooth Low Energy connection, either onboard or via a shield.
\item[Battery] A battery capable of providing enough current for the chosen microcontroller. The Arduino 101 draws around 70 mA when processing reasonably intensely.\cite{dsref3}
\end{description}

For my implementation, I used an \textbf{Arduino 101} board, which contains an Intel Curie module. It has the following specifications:\cite{dsref4}

\begin{description}
\item[Processor] 32MHz
\item[Memory] 24KB SRAM
\item[Storage] 196KB Flash memory
\item[Accelerometer] 6-axis IMU
\item[Bluetooth] Integrated BLE 
\item[Battery] A standard 9V battery
\end{description}

\subsubsection{Linux Computer}

The requirements of the computer are not onerous, and most of them are standard on just about all modern computers:

\begin{description}
\item[Processor] In order to train the network effectively, a faster processor than that of the microcontroller is necessary. 
\item[Memory] Likewise, the computer will need enough memory to hold the network. For any network which can be fitted onto the Flash (or other) memory of a microcontroller, this is unlikely to be a problem.
\item[USB Ports] At least one USB port is necessary to upload files to the microcontroller.
\item[Linux] I haven't tested any of the software on other operating systems, so a machine running a Linux variant is probably necessary.
\item[Software] A list of the necessary software can be found in the \todo{Project Management section (link)}
\end{description}

My machine, a 2013 Lenovo IdeaPad running Ubuntu 16.04, fulfills all of the above requirements.

\subsubsection{Android Phone}

Bluetooth Low Energy support was added in Android 4.3 (Jelly Bean MR2), with the Level 18 API.\cite{dsref5} Any phone running Android 4.3 or later, and which supports Bluetooth Low Energy, will suffice for this project.

My phone is a 2015 Huawei Nexus 6, running Android 7.1.2 (Nougat).

\subsection{Microcontroller Software Architecture}%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Software architecture \& UML diagrams etc for microcontroller}

\subsection{Linux Computer Software Architecture}%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Software architecture \& UML diagrams etc for computer}

\subsection{Android Phone Software Architecture}%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Software architecture \& UML diagrams etc for Android phone}

\subsection{Data Capture \& Format}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Data capture and *format specification*. Talk about Curie's IMU, and how to turn the stream of inputs into the desired format for the Neural network}

\subsubsection{Microcontroller Placement}

\todo[inline]{Where to pt the microcontroller while recording...}

\subsubsection{Log File Specification (Supervised)}

A supervised log file will be a \lstinline{.txt} file, and generally be called \lstinline{set}, followed by a numerical suffix, for example \lstinline{set3.txt}. It is recommended that log files be stored in folders such that it is obvious whose exercises have been recorded.

The format of the file will be as follows; zero or more instances of \emph{repetitions}, each consisting of:

\begin{itemize}
\item One or more lines with the values of the inputs.
\item A line with the text \lstinline{Repetition Start}
\item One or more lines with the values of the inputs.
\item A line with the text \lstinline{Repetition End}
\item One or more lines with the values of the outputs, one line per output node
\item One or more lines with the values of the inputs.
\end{itemize}

An example of a valid supervised log file can be found \todo[inline]{todo: link}

\subsubsection{Log File Specification (Unsupervised)}

An unsupervised log file will be a \lstinline{.txt} file, and generally be called \lstinline{set}, followed by a numerical suffix, for example \lstinline{set3.txt}. It is recommended that log files be stored in folders such that it is obvious whose exercises have been recorded.

The format of the file will be as follows; zero or more instances of \emph{repetitions}, each consisting of:

\begin{itemize}
\item A line with the text \lstinline{Motion detected after X milliseconds. Logging...}
\item One or more lines with the values of the inputs.
\item A line with the text \lstinline{Motion ended after Y milliseconds. Logging...}
\end{itemize}

Where X and Y are the intervals between the last motion detection event.

Prior to normalisation, the correct targets will need to be manually added to the log file.

An example of a valid unsupervised log file can be found \todo[inline]{todo: link}

\subsubsection{Normalised Log File Specification}

A normalised log file will be a \lstinline{.txt} file, and have the name of the set from which it was normalised, followed by the suffix \lstinline{_normalised}. For example, the normalised log file for the (raw) log file \lstinline{set1.txt} would be \lstinline{set1_normalised.txt}.

The format of the file will be as follows; zero or more instances of \emph{repetitions}, each consisting of:
\begin{itemize}
\item A line with the text \lstinline{Repetition Start}
\item One or more lines with the values of the inputs, with one line/value per input node. Each value will be equal to the \textbf{sum} of the raw input values
\item A line with the text \lstinline{Repetition End}
\item One or more lines with the values of the targets, with one line/value per output node.
\end{itemize}

There should be no blank lines between repetitions.

An example of a valid repetition can be found \todo[inline]{link}

\subsection{Neural Network Architecture}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The parameters of the neural network for exercise classification will be as follows:

\begin{description}
\item[Input Nodes: ] 20
\item[Hidden Nodes: ] 10
\item[Output Nodes: ] 3
\item[Learning Rate:] 0.3
\item[Momentum: ] 0.9
\item[Initial Weight Max: ] 0.5
\end{description}

\todo[inline]{Update parameters as necessary}

The network parameters were decided upon after experimentation with a variety of values - for more information on how these values were arrived at, see \todo[inline]{section?}

The network will be trained on \todo{number} examples (\todo{breakdown of numbers}), with a further \todo{another number} (\todo{breakdown}) kept back for validation.

For information on how the neural network will work, see the section on the neural network library. \todo[inline]{link}

\subsection{Training of Neural Network}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{How to train neural network on computer (and to get the network weights etc back onto the Curie}

\subsection{Classification by the Neural Network}%%%%%%%%%%%%%%%%%%%%%%%%%

Having returned a set of output values from the classifier, the following algorithm will be used to classify the result:

\begin{lstlisting}
Given a set of output values vs and a minimum classification threshold t
classificationIndex = -1
for each value v in vs \{
  if v > t \{
      classificationIndex = index(v,vs)
        t = v
    \}
\}
return classificationIndex
\end{lstlisting}

Where index(v,vs) is a function that returns the index of v in the set vs.

\todo[inline]{include code?}

The classification can then be transmitted to the phone for display (see below).

\subsection{Connectivity}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The microcontroller will communicate over a Bluetooth Low Energy connection with the phone. Upon classification, the microcontroller will send a single integer representing the (zero indexed) index of the output node corresponding to the classification, or the integer \lstinline{-1} if the input was not classifiable (see above for the specifics of the algorithm).

\subsection{Data Display}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In response to the integer transmitted by the microcontroller, the phone will display a message indicating the latest classification. The mapping between the integers and the messages to be displayed is as follows:
\begin{description}
\item[0] "Press Up"
\item[1] "Sit Up"
\item[2] "Lunge"
\item[-1] "Not Valid"
\item[default] "Unknown"
\end{description}

The inclusion of the default "Unknown" is intended to handle errors during transmission or classification.

On updating, the previous message will fade out and the new one fade in. This ensures that even if the same message is displayed twice in a row (a likely occurrence), the arrival of the new classification will be apparent.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Project Plan and Management}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section briefly details how I managed my project, and the tools and methodologies that I employed. 

Hardware specifications can be found \todo[inline]{in the Design and Spec section (link)}, while an evaluation of how the various tools and methodologies worked in practice can be found \todo[inline]{in the evaluation section (link)}

\subsection{Timetable}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Because the focus of my project changed significantly between the submission of my interim report and the submission of this report, my initial project timetable (as recorded in my interim report) is different to my revised project timetable. The revised project timetable is detailed below, while the initial timetable can be found in the appendices.\todo[inline]{Add initial timetable to appendices and link}

Because the revised timetable was only drawn up after the interim report, it contains no entries before March.

My timetable is organised by 'milestones' - each consisting of a set piece of implementation with a projected date for completion.

\subsubsection{End of research/start of implementation - 4/4/17}

Finish research so as to be ready to start implementation on time.

\subsubsection{Implementation of logging functionality - 14/4/17}

Finish implementation of a logging program to record example data and store it on computer in preparation for training.\todo[inline]{See relevant section and link}

Finishing this functionality early will enable data collection to continue alongside development, so that when I am ready to start training I will have a large enough data set to do so.

\subsubsection{Implementation of C++ neural network library - 28/4/17}

Reimplement ArduinoANN as a C++ library (see \todo[inline]{link to design section}). Additionally, implement a program to train an example of a network on the training data already connected, and do so.

\subsubsection{Implementation of classifier - 5/5/17}

Using the previously implemented neural network library, implement a classifier that runs on the Arduino and sends it's classifications back to the computer over Serial for display.

\subsubsection{Implementation of BLE functionality - 19/5/17}

Extend the classifier to send results over a BLE connection to a phone. Implement a program that runs on the phone and displays classifications sent over BLE from the Arduino.

\subsubsection{Implementation of multiple Curie networking (extension)- 2/6/17}

Train multiple networks to enable classification together, and adapt the classifier as necessary.
Extend the phone program to accept multiple BLE connections and display the results.

This milestone also acts as a buffer, giving an extra two weeks if the core implementation overruns without eating into the time to write the report.

\subsubsection{Report submission - 19/6/17}

Write the project report, and evaluate the classifier performance. 

\subsubsection{Presentation - 26/6/17}

Prepare for the project presentation, fixing bugs as necessary to make a demonstration work. 

\subsubsection{Project archive submission - 3/7/17}

Tidy up codebase and write user guide. Fix any remaining bugs and make programs more robust.

\subsection{Version Control}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{git}

I chose git\cite{ppref0} for my version control system, largely because of my prior experience with it. Within git, I used a variation of a standard workflow known as \textit{gitflow}.\cite{ppref1} 

I kept the convention of having separate \lstinline{master} and \lstinline{development} branches, but did not use release branches. 

In addition to these two branches, and the feature branches, I used two more long term branches:

The branch \lstinline{data} was created once the logging functionality was complete, and was used to track changes to the loggers and to track the recording of data. This branch was then merged to \lstinline{development} whenever necessary to make the data available for other branches.

The branch \lstinline{documentation} was created at the very start, and contains only documentation, in particular the project diary (\todo[inline]{link}) and both reports. While the projects were both written in Overleaf\todo[inline]{link}, the changes were transferred to the branch regularly.

\subsubsection{Github}

Much like git, I chose to use Github\cite{ppref2} to host my git repository largely because of my familiarity with it. 

I maintained a repository\cite{ppref3} for the duration of the project and stored virtually everything relating to my project in it.

\subsection{Languages \& Libraries Used}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The multi platform nature of this project meant that I used several languages for the various constituent parts/

\subsubsection{C++}

The core neural network code (for both the Linux and Arduino versions, see \todo[inline]{link} for details) was written in C++\cite{ppref4}. I also wrote the training and save/load code in C++.

I chose to follow the \lstinline{c++11}\cite{ppref5} standard to enable me to make use of the new \lstinline{std::vector<>} that was introduced with \lstinline{c++11}.

I used the C++ unit testing library \textit{Catch}\cite{ppref6} to write unit tests for my C++ code.

\subsubsection{Arduino}

While software for the Arduino can be written in any language which has a compiler capable of compiling a binary for the Arduino's processor, most Arduino programming is done in the Arduino C/C++ variant\cite{ppref7}, which takes file suffix \lstinline{.ino}. This variant adds some Arduino specific libraries\cite{ppref8}, but lacks many of the normal C/C++ libraries - most notably the C++ Standard Template Library (STL).\cite{ppref9}

The main Arduino programs were written in Arduino C++. I used the Intel libraries \textit{CurieIMU}\cite{ppref10} and \textit{CurieBLE}\cite{ppref11} to provide access to the Curie's IMU and BLE adapter respectively.

\subsubsection{Python}

I used Python\cite{ppref12} to write all of the necessary scripts for logging data on the computer, normalising data, and for compiling and running automated unit tests.

I used Python 2.7.12 for this project, but could have just as easily done it in Python 3.

Alongside the core Python modules \textit{sys, serial, os, subprocess} and \textit{random}, I made use of the \textit{curses}\cite{ppref13} module for terminal control.

\subsubsection{Java (Android)}

Android\cite{ppref14} programs are written in Java, which is then compiled for the Android Runtime (ART)\cite{ppref15}, instead of normal Java bytecode.

I wrote the Android phone programs to display data in Java.

\subsection{Tools Used}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{GCC}

All versions of the Gnu Compiler Collection (GCC) since GCC 4.8.1 have supported the C++11 standard\cite{ppref16}. I chose to use version 6.3.0\cite{ppref17} to compile all C++ code that runs on my computer.

\subsubsection{AVR-GCC}

To compile C/C++ code for the Arduino requires the AVR-GCC compiler. This comes bundled with the Arduino IDE\cite{ppref8} (see below).

All versions of the Arduino IDE since 1.6.6 have enabled C++11 by default.

\subsubsection{Arduino IDE}

Aside from allowing the user to edit code, the Arduino IDE\cite{ppref18} manages compilation and upload of programs to a connected Arduino.

I used version 1.8.2, but any version since 1.6.6 would have worked just as well.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Contribution/Deliverable Progress \& Completion}%%%%%%%%%%%%%%

\todo[inline]{Better name? Which deliverables did I actually deliver}

\subsection{Project Management}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{How well did my project management go, were the tools adequate, etc}
\todo[inline]{Remember to include diary in appendices and link to it}

\subsection{Classifier Performance}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{All the normal classification measures. Will probably need numbers for all the versions}

\subsection{Network Limitations}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{No training on Arduino is a blow}

\subsection{Energy Consumption}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{How long did the battery last? Is this practicable for the smaller form factor Curie etc}

\subsection{Stability \& Ease of Use}%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Does it crash? Is it easy to install and use?}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and Future Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Conclusion}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{What has *humanity* learned? What worked and what didn't, etc}

\subsection{Future Work}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Where can the technology go from here?}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Appendix 1: User Guide}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Installation}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{How to: install all the stuff. Ideally git repo + single script to install dependencies should be enough}

\subsection{Setup}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{How to get ready to classify (inc. training the network to match your movements, probably. If not this section becomes less useful).}

\subsection{Usage}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{How to: actually use the thing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Appendix 2: Examples and Code Samples}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Example Log Files}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Supervised Log File Example}

An example of a valid supervised log file is as follows (this example contains two repetitions, and there are two output nodes - the correct target is the first of the two):

\begin{lstlisting}
2112 3521 9697
 -820 4980 8498
 4928 1414 12078
 2182 2625 17658
Repetition Start
 420 6706 17109
 390 4711 18996
 34 4158 16245
 112 3384 18010
 -122 988 16876
 1132 1626 18761
 133 2256 17444
 1329 758 17024
 162 1943 14781
 260 2308 14217
 438 3703 14671
 1522 3522 8614
Repetition End
1
0
 267 1716 11535
 2021 2455 11427
 1941 2974 9327
 1187 3642 12921
 1484 624 13763
Repetition Start
 2301 4362 15325
 2448 786 14240
 1014 3284 17920
 1094 4471 17259
 3094 623 18312
 315 3334 16080
 1351 1072 20128
 2352 564 16417
 2270 66 17622
 1286 238 15131
 2303 2767 13679
 2078 2553 13658
 3072 3089 11358
 -1023 2758 10359
Repetition End
1
0
 2286 1498 10641
 1187 3017 11019
 938 2236 10331
\end{lstlisting}

\subsubsection{Unsupervised Log File Example}

An example of a valid unsupervised log file is as follows (this example contains one valid repetition and an unfinished one, which will be removed in the normalisation process):

\begin{lstlisting}
Motion detected after  794  milliseconds. Logging...
-3645 258 18409
 -1192 -1167 21047
 -2562 -3021 25236
 -2985 -4357 29204
 -1892 -6278 24810
 -1823 -4548 25039
 -347 -4235 22112
 -1465 -5232 24840
 -1546 -5415 26162
 -1849 -4882 22686
 -3693 -5339 22833
 -2114 -4549 21613
 -2126 -6574 21918
 -2303 -4939 20830
 -1795 -3754 19054
 -209 -2626 19330
 506 -460 19227
 874 -1628 17378
 -3168 -813 18150
 -4758 -501 17496
 595 1684 15219
 976 -1727 15472
 264 -629 19411
 Motion ended after  3018  milliseconds. Logging...
Motion detected after  784  milliseconds. Logging...
-2141 1791 16200
 -395 -237 17426
 -2397 164 19727
 -1568 -1193 22452
 -1612 -4823 26304
 -2882 -6720 26317
 -2768 -6063 24776
 -2561 -4488 23331
 -1143 -3689 23230
 -2256 -5549 23404
 -823 -3498 23925
 -1676 -6678 26284
\end{lstlisting}

\subsubsection{Normalised Log File Example}

An example of a valid repetition for a network with 20 input nodes and one output node is as follows:

\begin{lstlisting}
Repetition start
20119
20119
23526
25971
30233
33248
33248
34300
29982
29982
27556
25647
22664
17422
17422
17422
15862
15862
16160
18608
Repetition end
1
\end{lstlisting}

\subsection{Example Network Configuration Files}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Untrained Network}

\todo[inline]{Complete this}

\subsection{Trained Network}

This example shows a network that has undergone training. As such, the \lstinline{TrainingCycle} counter has increased, and some weights are now larger than the defined \lstinline{initialWeightMax}.

\begin{lstlisting}
#ifndef ARDUINO_CONFIG_H
#define ARDUINO_CONFIG_H

#include "avr/pgmspace.h"

const int numInputNodes = 20;
const int numHiddenNodes = 10;
const int numOutputNodes = 1;
const float learningRate = 0.300000;
const float momentum = 0.900000;
const float initialWeightMax = 0.500000;

// TrainingCycle (not needed on Arduino): 317

const float hiddenWeights[numInputNodes +1][numHiddenNodes] PROGMEM = {
    { -0.208936, 0.465415, -0.051608, 0.266630, 0.244777, -0.345782, 0.473185, 0.130999, -0.512141, 0.541225 }, 
    { -0.184242, -0.185961, 0.048651, -0.447796, -0.403301, -0.377087, -0.363783, -0.344564, 0.268100, 0.156894 }, 
    { -0.438798, -0.231550, -0.432171, 0.417060, 0.295765, 0.006337, 0.381011, -0.045423, 0.253946, -0.132465 }, 
    { 0.157203, -0.181294, -0.175319, 0.237207, 0.400133, -0.268108, -0.034001, 0.321978, -0.561890, 0.015838 }, 
    { 0.095073, -0.414909, 0.395242, 0.111011, 0.269341, -0.449858, 0.206365, 0.524708, -0.181234, -0.351355 }, 
    { -0.466847, -0.126106, 0.147103, -0.334612, -0.083822, -0.268722, -0.237934, -0.125875, -0.332713, -0.008082 }, 
    { 0.123222, -0.198338, -0.274432, 0.513173, 0.302451, -0.456392, 0.008966, 0.280207, -0.410660, 0.301137 }, 
    { -0.513978, 0.149379, -0.238859, -0.288574, 0.239729, -0.248091, 0.330426, -0.257049, 0.216124, 0.568632 }, 
    { -0.367217, -0.258441, -0.506060, -0.255655, -0.499114, 0.113885, 0.188771, 0.014348, 0.213099, -0.113877 }, 
    { -0.480785, -0.364806, -0.396680, 0.497976, -0.502551, 0.128596, -0.261498, 0.462252, -0.598261, 0.253812 }, 
    { -0.567159, 0.236277, 0.162137, -0.427903, 0.198453, -0.061932, -0.172801, 0.418995, -0.272858, -0.358574 }, 
    { 0.159899, -0.399958, 0.233211, -0.149129, 0.289593, -0.324470, 0.244713, 0.587779, 0.016516, 0.539349 }, 
    { 0.129768, 0.396204, 0.135740, 0.012989, -0.305828, -0.443811, -0.277537, -0.153022, -0.337330, 0.496737 }, 
    { -0.569687, 0.106501, -0.409859, -0.446173, -0.044025, 0.183276, 0.356145, 0.125618, -0.659715, 0.259530 }, 
    { -0.560354, -0.289071, 0.103752, -0.370594, 0.240134, -0.449281, 0.337401, 0.220689, -0.067533, -0.147390 }, 
    { -0.059864, -0.357426, 0.268295, -0.025435, 0.287175, -0.130794, -0.345558, -0.056022, -0.592401, 0.409725 }, 
    { 0.070506, 0.494606, 0.012306, 0.027240, -0.112442, 0.128436, -0.409556, 0.127022, 0.280491, 0.565825 }, 
    { 0.368003, -0.237027, -0.127455, -0.135200, 0.429812, -0.477968, 0.417062, 0.129507, -0.251470, -0.289104 }, 
    { 0.244408, -0.091057, -0.426142, 0.103974, -0.089830, 0.466919, -0.213426, -0.357478, -0.044970, -0.003307 }, 
    { -0.186364, -0.420361, 0.170605, 0.392511, 0.417764, -0.235246, 0.305627, -0.136452, -0.280800, 0.048744 }, 
    { -0.090482, -0.197617, 0.347492, -0.188813, 0.381779, -0.349393, -0.213947, -0.088926, -0.425888, 0.317125 }, 
};

const float outputWeights[numHiddenNodes +1][numOutputNodes] PROGMEM = {
    { 0.033657 }, 
    { 0.187269 }, 
    { 0.944105 }, 
    { 0.532517 }, 
    { 1.497310 }, 
    { 0.390718 }, 
    { 0.715542 }, 
    { 0.833513 }, 
    { 0.245622 }, 
    { 1.482894 }, 
    { 1.962036 }, 
};

#endif // ARDUINO_CONFIG_H
\end{lstlisting}


\subsection{Code Samples}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo[inline]{Code samples?}

\todo[inline]{Add additional things}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
\newpage
\addcontentsline{toc}{section}{Bibliography}

\begin{thebibliography}{9}

% Introduction references (inref#)

\bibitem{inref1}
\url{http://webarchive.nationalarchives.gov.uk/20170110165405/http://www.noo.org.uk/NOO_about_obesity/adult_obesity/UK_prevalence_and_trends}
\textbf{Public Health England / UK Government}
UK and Ireland obesity prevalence and trends
\\\textit{Accessed 7/6/2017}



% Background references (bgref#) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibitem{bgref0}
\url{https://ibug.doc.ic.ac.uk/courses}
\textbf{Imperial College London, Department of Computing}
CO395 Machine Learning course home page
\\\textit{Accessed 7/6/2017}

\bibitem{bgref1}
\url{http://people.sabanciuniv.edu/berrin/cs512/reading/mao-NN-tutorial.pdf}
\textbf{A.K Jain, J. Mao \& K. Mohiuddin, Michigan Stage University}
Artificial Neural Networks: A Tutorial
\\\textit{Accessed 7/6/2017}

\bibitem{bgref2}
\url{http://www.glyn.dk/download/Synopsis.pdf}
\textbf{F. Nelson}
Neural Networks - Algorithms and Applications
\\\textit{Accessed 7/6/2017}

\bibitem{bgref3}
\url{http://robotics.hobbizine.com/arduinoann.html}
\textbf{Author Unknown, Hobbizine}
A Neural Network for Arduino
\\\textit{Accessed 7/6/2017}

\bibitem{bgref4}
\url{http://www.cs.bham.ac.uk/~jxb/INC/nn.html}
\textbf{J.A. Bullinaria, School of Computer Science, University of Birmingham}
John Bullinaria's Step by Step Guide to Implementing a Neural Network in C
\\\textit{Accessed 7/6/2017}

\bibitem{bgref5}
Looking specifically at backpropagation, D.E. Rumelhart, G.E. Hinton and R.J. Williams were working on back propagation in neural networks in 1986 (see \url{https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf}), although much of their work was based on the earlier work of others, in particular Paul Werbos. 
The original Apple Macintosh, released in 1984, had a 7.83MHz processor and 128KB of RAM. (source: \url{http://oldcomputers.net/macintosh.html}, \textit{accessed 7/6/2017}
). For comparison, the Arduino 101 I am using runs at 32MHz, and 196KB of Flash memory, although it only has 24KB of SRAM. (source: \url{https://www.arduino.cc/en/Main/ArduinoBoard101}, \textit{accessed 7/6/2017}).

If devices such as smartphones are considered, the superiority in power is obvious.

\bibitem{bgref6}
\url{https://www-ssl.intel.com/content/www/us/en/wearables/wearable-soc.html}
\textbf{Intel}
Intel Curie Module home page
\\\textit{Accessed 7/6/2017}

\bibitem{bgref7}
\url{https://www.bluetooth.com/specifications/bluetooth-core-specification}
\textbf{Bluetooth}
Bluetooth core specification
\\\textit{Accessed 7/6/2017}

\bibitem{bgref8}
\url{https://www.fitbit.com/uk/smarttrack}
\textbf{Fitbit}
Fitbit SmartTrack Auto Exercise Recognition
\\\textit{Accessed 7/6/2017}

\bibitem{bgref9}
\url{https://www.android.com/intl/en_uk/wear/}
\textbf{Google}
Android Wear home page
\\\textit{Accessed 7/6/2017}

\bibitem{bgref10}
\url{https://www.google.com/fit/}
\textbf{Google}
Google Fit home page
\\\textit{Accessed 7/6/2017}

\bibitem{bgref11}
\url{http://optimize.fitness}
\textbf{Optimize Fitness}
Optimize Fitness home page
\\\textit{Accessed 7/6/2017}

\bibitem{bgref12}
\url{https://boltt.com/}
\textbf{Boltt}
Boltt home page
\\\textit{Accessed 7/6/2017}

\bibitem{bgref13}
\url{http://www.actofit.com/}
\textbf{Actofit Wearables}
Actofit home page
\\\textit{Accessed 7/6/2017}

\bibitem{bgref14}
\url{https://www.indiegogo.com/projects/actofit-redefining-fitness-tracking--3#/}
\textbf{Indiegogo}
Indiegogo campaign page for Actofit
\\\textit{Accessed 7/6/2017}

\bibitem{bgref15}
\url{http://focusmotion.io/}
\textbf{Focus Ventures}
FocusMotion home page
\\\textit{Accessed 7/6/2017}

\bibitem{bgref16}
\url{https://www.nerdfitness.com/blog/proper-push-up/}
\textbf{S. Kamb, Nerd Fitness}
How to do a Proper Push Up
\\\textit{Accessed 7/6/2017}

\bibitem{bgref17}
\url{https://breakingmuscle.com/learn/pimp-your-push-up-3-common-mistakes-and-5-challenging-variations}
\textbf{N. Tumminello, Breaking Muscle}
Pimp Your Push Up: 3 Common Mistakes And 5 Challenging Variations
\\\textit{Accessed 7/6/2017}

\bibitem{bgref18}
\url{https://www.youtube.com/watch?v=Eh00_rniF8E}
\textbf{S. Malin}
How to Do a Push Up Correctly
\\\textit{Accessed 7/6/2017}

\bibitem{bgref19}
\url{https://www.livestrong.com/article/487008-how-to-do-a-correct-sit-up/}
\textbf{A. Cespedes, Livestrong.com}
How to Do a Correct Sit-Up
\\\textit{Accessed 7/6/2017}

\bibitem{bgref20}
\url{http://www.military.com/military-fitness/fitness-test-prep/proper-technique-for-curl-ups}
\textbf{S. Smith, Military.com}
The Proper Technique for Curl-ups
\\\textit{Accessed 7/6/2017}

\bibitem{bgref21}
\url{http://www.mensfitness.com/weight-loss/burn-fat-fast/situp}
\textbf{N. Green, Men's Fitness}
The Situp
\\\textit{Accessed 7/6/2017}

\bibitem{bgref22}
\url{https://www.livestrong.com/article/539595-how-to-do-sit-ups-without-anchoring-your-feet/}
\textbf{A. Cespedes, Livestrong.com}
How to Do Sit-Ups Without Anchoring Your Feet
\\\textit{Accessed 7/6/2017}

\bibitem{bgref23}
\url{https://www.youtube.com/watch?v=jDwoBqPH0jk}
\textbf{M. Tapper, Howcast}
How to Do a Sit-Up Properly
\\\textit{Accessed 7/6/2017}

\bibitem{bgref24}
\url{http://www.shape.com/fitness/workouts/know-your-basics-how-do-lunge}
\textbf{POPSUGAR Fitness}
Know Your Basics: How to Do a Lunge
\\\textit{Accessed 7/6/2017}

\bibitem{bgref25}
\url{https://www.youtube.com/watch?v=jzbXc2OmRMk}
\textbf{30 Day Fitness Challenges}
How To Do The lunge Exercise
\\\textit{Accessed 7/6/2017}

% Neural Network library references (nnref#) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibitem{nnref0}
\url{https://isocpp.org/wiki/faq/cpp11}
\textbf{Standard C++ Foundation}
C++11 Overview and FAQ
\\\textit{Accessed 8/6/17}

\bibitem{nnref1}
\url{http://www.nongnu.org/avr-libc/user-manual/group__avr__pgmspace.html}
\textbf{avr-libc contributors (see \url{http://www.nongnu.org/avr-libc/user-manual/index.html})}
Program Space Utilities
\\\textit{Accessed 12/6/17}


% Design and Specification references (dsref#) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibitem{dsref0}
Figure calculated as follows: On an Arduino 101 (32MHz clock speed), classification took an average of 658 microseconds, so the minimum clock speed necessary is given by 32 * 0.658 / 100 = 211 KHz

\bibitem{dsref1}
Calculations for memory usage

\bibitem{dsref2}
The 'BareMinimum' example sketch uses 48432B of program memory. The classifier sketch uses 65456B of program memory, a difference of 17033B.

\bibitem{dsref3}
\url{https://tlextrait.svbtle.com/arduino-power-consumption-compared}
\textbf{T. Lextrait}
Arduino: Power Consumption Compared
\\\textit{Accessed 11/6/17}

\bibitem{dsref4}
\url{https://www-ssl.intel.com/content/dam/support/us/en/documents/boardsandkits/curie/intel-curie-module-datasheet.pdf}
\textbf{Intel}
Intel Curie Module Datasheet
\\\textit{Accessed 10/6/17}

\bibitem{dsref5}
\url{https://developer.android.com/about/versions/android-4.3.html#Wireless}
\textbf{Google}
Android 4.3 API Guide
\\\textit{Accessed 10/6/17}

% Project Plan and Management references (ppref#)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibitem{ppref0}
\url{https://git-scm.com/}
\textbf{Git }
Git home page
\\\textit{Accessed 8/6/17}

\bibitem{ppref1}
\url{https://www.atlassian.com/git/tutorials/comparing-workflows#gitflow-workflow}
\textbf{Author unknown, Atlassian}
Comparing Workflows
\\textit{Accessed 8/6/17}

\bibitem{ppref2}
\url{https://github.com/}
\textbf{Github Inc}
Github home page
\\\textit{Accessed 8/6/17}

\bibitem{ppref3}
\url{https://github.com/walrus/walrus}
\textbf{D. Clay ('walrus')}
WALRUS (project) Github repository
\\\textit{Accessed 8/6/17}

\bibitem{ppref4}
\url{https://isocpp.org/}
\textbf{Standard C++ Foundation}
Isocpp home page
\\\textit{Accessed 8/6/17}

\bibitem{ppref5}
\url{https://isocpp.org/wiki/faq/cpp11}
\textbf{Standard C++ Foundation}
C++11 Overview and FAQ
\\\textit{Accessed 8/6/17}

\bibitem{ppref6}
\url{https://github.com/philsquared/Catch}
\textbf{P. Nash ('philsquared')}
Catch Github repository
\\\textit{Accessed 8/6/17}

\bibitem{ppref7}
\url{https://www.arduino.cc/en/Reference/HomePage}
\textbf{Arduino AG}
Arduino Language Reference
\\\textit{Accessed 8/6/17}

\bibitem{ppref8}
\url{https://www.arduino.cc/en/Hacking/BuildProcess}
\textbf{Arduino AG}
Arduino Build Process
\\\textit{Accessed 8/6/17}


\bibitem{ppref9}
\url{http://www.arduinolibraries.info/types/official}
\textbf{Arduino Library List}
Official Libraries
\\\textit{Accessed 8/6/17}

\bibitem{ppref10}
\url{https://www.arduino.cc/en/Reference/CurieIMU}
\textbf{Arduino AG / Intel}
CurieIMU Reference
\\\textit{Accessed 8/6/17}

\bibitem{ppref11}
\url{https://www.arduino.cc/en/Reference/CurieBLE}
\textbf{Arduino AG / Intel}
CurieBLE Reference
\\\textit{Accessed 8/6/17}

\bibitem{ppref12}
\url{https://www.python.org/}
\textbf{The Python Software Foundation}
Python home page
\\\textit{Accessed 8/6/17}

\bibitem{ppref13}
\url{https://docs.python.org/2/library/curses.html#module-curses}
\textbf{The Python Softwaer Foundation}
Curses documentation home
\\\textit{Accessed 8/6/17}

\bibitem{ppref14}
\url{https://developer.android.com/guide/index.html}
\textbf{Google}
Introduction to Android
\\\textit{Accessed 8/6/17}

\bibitem{ppref15}
\url{https://source.android.com/devices/tech/dalvik/}
\textbf{Google}
ART and Dalvik
\\\textit{Accessed 8/6/17}

\bibitem{ppref16}
\url{https://gcc.gnu.org/projects/cxx-status.html#cxx11}
\textbf{The GNU Project}
C++11 Support in GCC
\\\textit{Accessed 8/6/17}

\bibitem{ppref17}
\url{https://gcc.gnu.org/gcc-6/}
\textbf{The GNU Project}
GCC 6 Release Series
\\\textit{Accessed 8/6/17}

\bibitem{ppref18}
\url{https://www.arduino.cc/en/Main/Software}
\textbf{Arduino AG}
Arduino main software page
\\\textit{Accessed 8/6/17}

\bibitem{ppref19}
\url{}
\textbf{}
\\\textit{Accessed 8/6/17}

\bibitem{ppref20}
\url{}
\textbf{}
\\\textit{Accessed 8/6/17}

\bibitem{ppref21}
\url{}
\textbf{}
\\\textit{Accessed 8/6/17}


\bibitem{ppref22}
\url{}
\textbf{}
\\\textit{Accessed 8/6/17}

\bibitem{ppref23}
\url{}
\textbf{}
\\\textit{Accessed 8/6/17}


\bibitem{ppref24}
\url{}
\textbf{}
\\\textit{Accessed 8/6/17}

\bibitem{}
\url{}
\textbf{}
\\\textit{Accessed 8/6/17}

% Evaluation references (evref#) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibitem{}
\url{}
\textbf{}


% Conclusions and future work references (fwref#) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibitem{}
\url{}
\textbf{}
\\\textit{}

\end{thebibliography}

\end{document}
